# ループを閉じた話。


ものをつくっていると、
「学習する仕組み」がほしくなる瞬間があるんですよね。

同じ間違いを何度も直している自分に気づいたとき。

ぼくの場合、それは文字起こしでした。



ぼくはひとりで動画編集ツールをつくっています。

長いYouTube動画からショート動画を自動で切り出す。
AIが中身を分析して、面白い箇所を見つけて、
文字起こしして、テロップを載せる。

でもAIの文字起こしは完璧じゃない。

固有名詞を間違える。
句読点の位置がおかしい。
切り取りの始点が中途半端。

だからぼくが直す。毎回、手で。

この「手で直す」の中に、
次の生成を良くするヒントが全部詰まっている。

問題は、その仕組みをどうつくるか。

アプリには、ユーザーの目に映る「表」の部分と、
目に見えない「裏」の部分がある。

ボタンやテロップ編集画面が「表」。
データの保存、AIの実行、差分の計算が「裏」。

エンジニアはこの裏側のことをバックエンドと呼びます。

今回は、このバックエンドを
どう設計したかという話です。



まず考えたのは、データの流れです。

動画がショートになるまでに、
いくつかの工程を順番に通っていく。

工場の流れ作業に近いですね。
ある工程の出力が、次の工程の入力になる。

こういう流れ作業の構造を、
パイプラインと言います。

ぼくのツールのパイプラインは、
4つの層に分かれています。

1層目はワーカー。
裏方の作業員みたいなもので、
動画を受け取って、文字起こしして、
ハイライトを抽出して、
ショート動画の設計図を組み立てる。
結果はJSONという形式のファイルに保存される。
JSONは、データを整理して書き出すための共通書式ですね。

2層目はAPI。
表側と裏側をつなぐ窓口です。
テロップの編集、評価の送信、承認。
画面からの操作はすべてこの窓口を通る。

3層目はラーニング。名前のとおり、学習を担う層。
差分の収集、辞書の構築、フィードバックの集計。

4層目はアナリシス。
AIに渡す指示書、いわゆるプロンプトを組み立てる。
ここに3層目の学習結果が注入される。

データは1層目で生まれて、2層目で修正されて、
3層目で学習データになって、4層目で次の生成に影響する。

このパイプライン全体を
ひとつのループとしてつなげるのが、今回の設計でした。



最初の難所は、1層目のワーカーにありました。

AIが文字起こしを生成して、
ブループリントをJSONに保存する。

ブループリントというのは設計図のことで、
どの区間を切り出すか、テロップに何を表示するか、
タイミングはどうするか、
そういった情報がまとまったものです。

ただ、保存した瞬間に
画面からの編集が始まる。

テロップを直す。テキストを変える。
保存するたびにJSONが更新される。

つまり、AIが最初に出した結果が、
編集のたびに上書きされていく。

あとから「元はどうだったか」を知りたくても、
もう消えている。

だから、ワーカーがJSONを保存した直後に、
タイムラインのスナップショットを
別のフィールドに凍結するようにした。

スナップショットは「その瞬間の写し」。
フィールドはJSONの中の一区画のことです。

_original_timelineという名前をつけた
この区画には、誰も触れない。

編集画面からも、APIからも、上書きできない。
生成直後の状態が、そのまま残り続ける。



2層目のAPIには、
2つのエンドポイントをつくりました。

エンドポイントというのは、
窓口に設けた受付口のことです。
用件ごとに別の窓口があるイメージですね。

ひとつは承認用のエンドポイント。

ユーザーが「Approve」を押すと、
凍結しておいた_original_timelineと、
編集後の現在のタイムラインを並べて比較する。

テキストがどう変わったか。
タイミングがどう修正されたか。
セグメントが追加されたか、削除されたか。

セグメントというのは、
動画を区切ったひとつひとつの塊。
テロップ1枚分に相当する単位です。

差分はセグメントごとに計算して、
学習レコードとしてラーニング層に渡す。

もしユーザーが一文字も直していなければ、
confirmed_correctというラベルがつく。
「AIが正しかった」という意味です。

大きく直していればuser_improved。
「ユーザーが改善した」。

このラベルがあると、あとから
正解だったケースと間違いだったケースを
分けて分析できる。



もうひとつはフィードバック用のエンドポイント。

Goodか、NGか。

NGの場合は、理由タグを一緒に送れるようにした。
transcription、segmentation、length、contentの4つ。

順に、文字起こし、切り取り位置、長さ、内容。

理由タグはオプショナル、つまり任意にしている。
選ばなくても送信できる。

必須にすると面倒になって、
フィードバック自体をしなくなるから。



3層目のラーニングには、
2つのモジュールを置きました。

モジュールというのは、
ひとつの役割を受け持つ部品のこと。
レゴブロックみたいに、
それぞれ独立した機能を持っています。

ひとつ目はdiff_collector。
差分を集める部品です。

承認時に送られてくる学習レコードを
JSONファイルに追記していく。

そしてレコードが溜まると、
テキストの修正パターンを分析する。

元のテキストと修正後のテキストを単語単位で比べて、
3回以上修正された単語を辞書に登録する。

同じ固有名詞を何度も直しているなら、
それはAIが繰り返し間違えている証拠。

辞書に入れておけば、
次の文字起こしのあとに自動で正しく置き換わる。



ふたつ目はfeedback_insights。
フィードバックから洞察を引き出す部品です。

NG理由タグを集計して、
プロンプトに追記するためのテキストを自動で組み立てる。

プロンプトは、AIへの指示書のこと。
「こういうふうに文字起こしして」
「こういう箇所を見つけて」という指示が書いてある。

30件以上のフィードバックが溜まると、
各理由の割合を計算して、
最も多い理由に対応する改善指示を組み立てる。

30件未満なら何もしない。
少ないデータで下手に動くと、
たまたま続いた傾向に引きずられるから。

この「一定数が溜まるまで動かない」仕組みを、
閾値と言います。ハードルのようなものですね。



4層目のアナリシスでは、
AIに渡すシステムプロンプトを組み立てています。

システムプロンプトは、
ユーザーの入力よりも先に読み込まれる、
AIの「性格設定」のような指示書です。

ここが、ループが閉じる場所。

プロンプトを組み立てるとき、
feedback_insightsが生成した改善テキストがあれば、
それをプロンプトの末尾に追記する。

なければ何も追記しない。

これで、フィードバックが溜まるほど
AIの指示が具体的になっていく。

最初は汎用的な指示しかないけれど、
使い込むほどに、
「このユーザーがよく直すポイント」が
プロンプトの中に染み出してくる。



全体を俯瞰すると、
データの流れは一方通行じゃないんですよね。

ワーカーが生成して、
APIで差分を取って、
ラーニングが蓄積して、
アナリシスがプロンプトに反映して、
またワーカーが生成する。

出力が入力に戻ってくる。
パイプラインが、ループになっている。



これを組んでみて思ったのは、
バックエンドの設計って、
結局「データの居場所」の設計なんだということ。

_original_timelineをどこに保管するか。
差分をいつ計算するか。
学習レコードをどの粒度で保存するか。
辞書をどのタイミングで適用するか。

ロジックは単純なんです。
比較して、数えて、書き出すだけ。

難しいのは、データの居場所を決めること。

居場所を間違えると、
あったはずのデータが消えていたり、
使いたいタイミングで手元になかったりする。



もし今、何かの学習する仕組みをつくろうとしているなら。

まず、データの流れを一本の線で描いてみてください。

生まれて、変形されて、蓄積されて、
また入口に戻ってくる。

その線の途中に、
データが消える場所がないかを確認する。

ループを閉じるというのは、
線を円にすることなんです。

どこかが途切れていたら、
それはまだ線のまま。
