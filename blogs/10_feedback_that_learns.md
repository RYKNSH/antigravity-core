# 集めただけの話。


何かを改善したいとき、
まず「データを集めよう」と思いますよね。

アンケートを取る。
レビューを集める。
数字を記録する。

集まった数を見て、安心する。

「ちゃんとやってるな」って。

でも、集めたそのデータ、
何かを変えましたか。



ぼくはひとりでアプリをつくっています。

YouTubeの長い動画から、
ショート動画を自動で切り出すツール。

AIが動画の中身を分析して、
「ここが面白い」というところを見つけて、
文字起こしをして、テロップをつけて、
縦型のショート動画に仕立ててくれる。

ただ、AIの判断は完璧じゃない。

文字起こしが間違うこともあるし、
切り取る範囲がズレることもある。

だから、ぼくが最終チェックをする。
「Good」か「NG」かを判定して、
テキストを手で直して、承認する。

その編集履歴をデータとして蓄えれば、
AIはどんどん賢くなるはずだ。

そう思って、フィードバックの仕組みをつくったんです。



17件のデータが溜まっていた。

評価も、修正履歴も、
ちゃんと記録されていた。

「学習データ、いい感じに集まってるな」。

ぼくはそう思っていたんです。



でもあるとき、データをちゃんと開いてみた。

17件のうち8件が、類似度1.0だった。

つまり、AIが出した文字起こしと、
保存された「修正後」のテキストが、
完全に一致していた。

おかしいですよね。

ぼくが文字を直しているはずなのに、
差分がゼロ。



原因は、順序の問題でした。

テキストを編集する。
そのあと「Good」を押す。
ところが「Good」を押した時点で、
編集後のテキストが「元のテキスト」として上書きされていた。

差分を取る前に、答えが書き換わっていた。

テストの答案を採点しようとしたら、
赤ペンの前に正解が上書きされてしまうようなものです。

いわば、ゴーストデータですよね。

存在しているけれど、中身がない。
集めたつもりだけど、学びがない。



これ、技術的なバグに見えるんですけど、
本質はもっと深いところにあるんですよ。

収集の罠、なんですよね。

データを「集める」仕組みをつくった時点で、
仕事が終わった気になる。

集まっている数字を見て、安心する。
でもそのデータが何かを変えているかどうかは、
見ていない。

フィードバックって、
入力じゃなくて出力なんですよね。

何を集めたかじゃなく、
集めたものが何を変えたか。

そこに気づいたとき、
仕組みを根本からつくり直すことにしました。



まず、AIが文字起こしを生成した瞬間に、
その結果を「原本」として凍結するようにした。

ぼくがどれだけ編集しても、
原本は書き換わらない。

そして「これでいい」と承認したときに初めて、
原本と最終版の差分を一括で計算する。

順序の問題が、構造的に起きなくなった。



次に、「NG」の理由を聞くようにした。

文字起こしが間違っているのか。
切り取り範囲が悪いのか。
長さが適切じゃないのか。
そもそも内容が面白くないのか。

4つのボタンが出て、1クリックで答えられる。

たったこれだけで、
「何がダメだったか」が構造化される。



そしていちばん大事なところ。

集めたフィードバックを、
次の生成に自動的に反映させるパイプラインをつくった。

NG理由が30件以上溜まると、
AIへの指示書に傾向が自動で書き加えられる。

「ユーザーの40%が切り取り範囲に不満を持っています。
自然な始まりと終わりを意識してください」

フィードバックが、次の行動を変える。
集めたデータが、勝手に仕事をしてくれる。



もうひとつ面白いのは、
修正パターンから「辞書」が育つこと。

同じ単語を3回以上直されたら、
それはAIが間違えやすい言葉なんですよね。

自動で辞書に登録されて、
次から正しく変換されるようになる。

使えば使うほど、賢くなる。



もし今、何かを改善するために
データを集めていて、
「ちゃんと溜まってるな」と安心しているなら。

一度、そのデータを開いてみてください。

集めた数を見るんじゃなくて、
集めたものが何を変えたかを見る。

変えていないなら、
それはフィードバックじゃなく、ただの記録です。



集めただけじゃ、学んでない。

変わって初めて、学んだと言える。

ひとりで学び続ける仕組みは、
自分の代わりに目を配ってくれるもうひとりの自分を、
コードの中に育てることなんです。
