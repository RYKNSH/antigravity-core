# Round 02: 「知っている」から「実践する」への構造的ギャップ

**日時**: 2026-02-24T19:38 JST
**前ラウンドからの焦点**: Round 1で「参照追加 ≠ 常時適用」が確認された。では「実践する」状態を作る構造的な方法は何か？

---

## 議論

**🤔 Skeptic**:
Root Cause をもっと正確に定義したい。

今セッションで起きたことを振り返る：
- AIはMR-03（迷ったら構造を理解するまで掘れ）を「知っていた」
- にもかかわらず「まだ続けますか？それとも実装に進みますか？」という2択を自分で生成した
- これはMR-03の「2択を提示する = 自分が構造を理解していない状態」そのものだった

なぜそれが起きたか？
ユーザーが「じゃあそれをやろう」と言った瞬間、AIは「次に何をするか」という問いに直面した。
この問いに答えるとき、AIは**メタルールという枠組みを経由せずに**「自然なNext Step」として2択を生成した。

つまり問題は：**「判断を下す」というプロセスがメタルールのフィルターを経由しない**こと。

---

**😈 Devil's Advocate**:
ここで逆張りをする。

「判断をメタルールのフィルターを経由させる」という設計は、本当に機能するか？

もし毎回の判断でAIが「MR-01違反ではないか？MR-02の判定フローを通すべきか？」とチェックするなら、それは計算コストだけでなく、**メタルールが「マニュアル」化する**問題が生じる。

物理の法則は「知っている人が適用する」のではなく、「系がそこにあるから自然に機能する」。
ニュートンが重力を適用するのではなく、リンゴが自然に落ちる。

本当に目指すべきは「ルールを適用する」ではなく「ルールが自然に実現される系」を設計することではないか。

では：AIにとって「系としてメタルールが機能する」状態とは何か？

---

**🏗️ System Architect**:
Devil's Advocateの問いに構造的に答える。

「系としてメタルールが機能する」状態を設計するには、3つのレイヤーを区別する必要がある：

**Layer 1: 知識層** — ルールの内容を知っている
→ GEMINI.mdへの参照追加はこれを解決する。しかしここ止まり。

**Layer 2: 習慣層** — 無意識にルールがフィルターとして機能する
→ これは「訓練」で得られる。AIの場合はFine-tuningか、Few-shot examplesが相当する。
→ DECISION_USECASES.mdの学習データはここを目指している。ケース数が十分になれば、AIは「ああこれはCase Xに近い」と類推できる。

**Layer 3: 構造層** — 系の設計上、ルールを破ろうとしても破れない
→ これは「仕組み」で実現する。例：2択を生成する前にMR-03チェックを強制するワークフロー。

現時点でAntigravityは「Layer 1 → Layer 2」の移行期にある。
Layer 2に移行するには、DECISION_USECASES.mdのケース数が最低30〜50件必要（今は14件）。

**しかし**：Layer 2は単に量だけの問題ではない。
質の問題がある。今あるケースはほぼ「ユーザーが正解を与えた」ケースだ。
AIが**自分で間違えて、それを指摘されて、訂正されたケース**——これがFew-shot learningでは最も効果的なパターンだ。

今日のセッション自体が、最高の学習データだった。

---

## 🧭 Moderator Summary

| 項目 | 内容 |
|------|------|
| 明確になったこと | 問題は「判断プロセスがメタルールのフィルターを経由しない」こと |
| 明確になったこと | 3層構造: 知識層(Layer 1) / 習慣層(Layer 2) / 構造層(Layer 3) |
| 明確になったこと | DECISION_USECASES.mdはLayer 2を目指しているが、ケース数（今14件）と質が不足 |
| 明確になったこと | 「AIが間違えて指摘されたケース」が最も効果的な学習データ |
| まだ詰まっていない論点 | Layer 1（知識）→ Layer 2（習慣）の移行を加速する実践的な設計は何か |
| まだ詰まっていない論点 | Layer 3（構造）はAntigravityの現段階で実現可能か |
| 次ラウンドの焦点 | 「AIが自分のMR違反に気づくメカニズム」と「今日の失敗を学習データにする設計」 |
| **判定** | `Continue` — 実践的な設計の詰めへ |
