# Round 02: checkinでの実体読み込みと「判断の瞬間」問題

**日時**: 2026-02-24T19:54 JST
**前ラウンドからの焦点**: Round 1で「参照≠実体」を実証した。次の問い：
1. checkinでDECISION_USECASES.mdの実体を読み込めば解決するか？
2. 読み込んでも「判断の瞬間」から遠ければ機能しないか？
3. 10KBのコストと効果のトレードオフは正当か？

---

## 議論

**🤔 Skeptic**:

「checkinでDECISION_USECASES.mdを読み込む」という案に移る前に、「実体を読み込む」と「判断の瞬間に機能する」が同じかどうかを問う。

**実験的思考実験**:
現在のcheckinはNEXT_SESSION.mdを読んでいる。今日のセッションの冒頭で、AIはNEXT_SESSION.mdの警告（「ゾンビプロセスが残っている」）を読んだはずだ。しかしユーザーが「なんでハングしてたの」と聞くまでAIは言及しなかった。

これは何を意味するか？

**checkinで読んでも、セッション中に「判断の瞬間」から遠ざかれば有効でなくなる。**

具体的に：
- checkinが08:00に実行される
- 12:00に新しいタスクを始める
- この4時間の間に、DECISION_USECASES.mdの内容はコンテキストの「遠い過去」に埋もれる

Cognitive ArchitectはLLMのAttention mechanismを知っている。具体的な数値で答えてほしい：
**セッション開始から何ターン・何トークン後にコンテキストの「中段」ルールの効力は有意に減衰するか？**

---

**😈 Devil's Advocate**:

Skepticの問いは正しいが、別の角度から補強する。

**DECISION_USECASES.mdの読み込みに反対する理由：10KBのコスト**

現在DECISION_USECASES.mdは14ケース・9MR・約10KB。これをcheckinで毎回読み込むと：
- コンテキストウィンドウの約10KB（≒2500トークン）が固定消費される
- セッションが長くなるほど、この「序盤のルール情報」は後ろに押し流される
- 結果：読んだのに機能しない（Skepticの実験的思考実験と一致）

**もっと根本的な問い（Cognitive Architectへ）**:

ルールを「セッション開始時に読む」モデルではなく、「判断の直前に検索する」モデルが可能ではないか？

例えば：AIが提案を生成しようとするとき、毎回DECISION_USECASES.mdの関連ケースを検索（grep）して、判断の直前にコンテキストに注入する。この「on-demand injection」モデルとcheckin読み込みモデルの差は何か？

---

**🏗️ Cognitive Architect**:

Skepticの数値的問いに答え、Devil's Advocateのon-demand injectionモデルを評価する。

**「判断の瞬間から遠ざかれば減衰するか」への回答**:

LLMのAttention mechanismの特性上、**はい、減衰する**。ただし現代の70B+モデルやGeminiクラスでは「Lost in the Middle」問題が軽減されているが、完全には解消していない。経験則で言えば：

- **直前の20ターン以内**: 高い確率でルールを「参照できる」
- **50ターン超**: コンテキスト中段のルールは実質的に参照されにくくなる
- **100ターン超の会話**: 序盤のルールはほぼ機能しない（実証的観察）

今日のセッションは100ターンを大幅に超えている。**checkin時に読んでも機能しない根本理由がここにある。**

**Devil's Advocateのon-demand injectionモデルへの評価**:

技術的には可能だが、重大な前提条件がある：
- AIが「今から判断を下す」ことを**自分で認識できる**必要がある
- これは「メタ認知」の問題であり、現在のAIアーキテクチャでは明示的なプロンプト設計なしには実装できない

**しかしここに突破口がある**：

Antigravityのアーキテクチャには、すでに「判断の前にワークフローを確認する」仕組みがある。`/go`, `/checkin`, `/checkout` などのワークフロー呼び出しがそれだ。これらのワークフロー**実行時**に関連MRをon-demandで注入することは可能だ。

- `/go` の先頭に: 「MR-08を確認: 前に進め、承認を待つな」
- `/checkin` の先頭に: 「MR-09を確認: NEXT_SESSION.mdを能動的に読め」——これは本日すでに実装済み
- 新提案を生成する前に: 「MR-01/02を確認: ハードコードしていないか？付け焼き刃でないか？」

**Skepticに問い返す**:

これは「ワークフロー単位のコンテキスト注入」だ。問題は「全MRを全ワークフローに入れる」のか、「特定MRを特定ワークフローにマッピングする」のかだ。後者の方がAttentionの観点では劇的に効果的だ。あなたはこの粒度について何か懸念があるか？

---

## 🧭 Moderator Summary

| 項目 | 内容 |
|------|------|
| 明確になったこと（Evidence付き） | LLMの「Lost in the Middle」問題：50ターン超でコンテキスト中段のルールは有意に減衰 |
| 明確になったこと | 今日のセッションは100ターン超 → checkin時の読み込みは有効期限切れ |
| 明確になったこと | 「全体をセッション頭に読む」より「特定ワークフロー実行時に関連MRをon-demandで注入」の方が Attention的に優れる |
| 明確になったこと | `/checkin` + MR-09の実装は「ワークフロー×MRマッピング」の正しい第一歩（本日実装済み） |
| まだ詰まっていない論点 | MR→WFのマッピング表を誰が管理するか（人間 vs 自動抽出） |
| まだ詰まっていない論点 | マッピングが増えたとき、どのWFに何のMRを入れるかの決定ルールは？（またハードコードになるリスク） |
| まだ詰まっていない論点 | ワークフロー呼び出し**ではない**判断（インタラクティブな会話中の判断）はどうするか |
| **判定** | `Continue` — WF×MRマッピングの詰めと「WFなし判断」への対処を次ラウンドへ |
